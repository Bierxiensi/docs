(window.webpackJsonp=window.webpackJsonp||[]).push([[118],{510:function(t,a,r){"use strict";r.r(a);var s=r(28),e=Object(s.a)({},(function(){var t=this,a=t.$createElement,r=t._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h2",{attrs:{id:"transformer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#transformer"}},[t._v("#")]),t._v(" Transformer")]),t._v(" "),r("h4",{attrs:{id:"引入"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#引入"}},[t._v("#")]),t._v(" 引入")]),t._v(" "),r("p",[t._v("2018年谷歌团队提出了生成词向量算法BERT，其核心即为Transformer")]),t._v(" "),r("h4",{attrs:{id:"组成"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#组成"}},[t._v("#")]),t._v(" 组成")]),t._v(" "),r("p",[t._v("自注意力机制"),r("code",[t._v("Self-Attention")]),t._v("和前馈神经网络"),r("code",[t._v("Feed Forward Neural Network")])]),t._v(" "),r("h4",{attrs:{id:"工作机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#工作机制"}},[t._v("#")]),t._v(" 工作机制")]),t._v(" "),r("p",[t._v("对数据进行编码，捕获给定单词与其前后单词之间的关系")]),t._v(" "),r("h4",{attrs:{id:"优点"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[t._v("#")]),t._v(" 优点")]),t._v(" "),r("p",[t._v("结合了CNN和RNN的优点")]),t._v(" "),r("ul",[r("li",[t._v("可以理解很远的序列元素之间的关系（克服了RNN缺点）")]),t._v(" "),r("li",[t._v("对序列中所有元素给予同样关注（自注意力机制？）")]),t._v(" "),r("li",[t._v("处理速度快（大模型算力消耗在并行计算，而MLP有利于并行计算？）")]),t._v(" "),r("li",[t._v("几乎可以处理任何序列数据（克服了CNN缺点）")]),t._v(" "),r("li",[t._v("可以实现上下文预测")]),t._v(" "),r("li",[t._v("有利于异常检测")])]),t._v(" "),r("h2",{attrs:{id:"注意力模型《attention-model》-am"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#注意力模型《attention-model》-am"}},[t._v("#")]),t._v(" 注意力模型《Attention Model》（AM）")]),t._v(" "),r("h4",{attrs:{id:"引入-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#引入-2"}},[t._v("#")]),t._v(" 引入")]),t._v(" "),r("p",[t._v("最早出现在机器翻译中，目前广泛使用在自然语言处理、统计学习、语音、计算机视觉")]),t._v(" "),r("h4",{attrs:{id:"功能-有选择的将注意力集中在某些部分-忽略其他不相关信息-有助于感知"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#功能-有选择的将注意力集中在某些部分-忽略其他不相关信息-有助于感知"}},[t._v("#")]),t._v(" 功能：有选择的将注意力集中在某些部分，忽略其他不相关信息，有助于感知")]),t._v(" "),r("h4",{attrs:{id:"优势"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#优势"}},[t._v("#")]),t._v(" 优势：")]),t._v(" "),r("ul",[r("li",[t._v("自然语言处理的新技术")]),t._v(" "),r("li",[t._v("提高了神经网络的可解释性")]),t._v(" "),r("li",[t._v("有助于克服RNN存在的一些问题")])])])}),[],!1,null,null,null);a.default=e.exports}}]);